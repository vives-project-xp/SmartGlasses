{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "import mediapipe.python.solutions.hands as mp_hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Dataset wortel (na jouw download & extract scripts)\n",
    "DATASET_ROOT = \"./images/dataset\"   # mappen: 0..9, a..z\n",
    "ASSERT_JSON = (\"landmarks.json\", \"landmarks_all.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996706a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = sorted(d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d)))\n",
    "print(\"Labels:\", label_map)\n",
    "\n",
    "classes = label_map\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "idx_to_class = {i: cls_name for i, cls_name in enumerate(classes)}\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "os.makedirs(\"./annotations\", exist_ok=True)\n",
    "with open(\"./annotations/label_map.json\", \"w\") as f:\n",
    "    json.dump({\"class_to_idx\": class_to_idx}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778981ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: preprocess helpers\n",
    "\n",
    "MCP_IDX = [5, 9, 13, 17]   # niet strikt nodig, maar handig\n",
    "def preprocess_landmarks(lms: List[Dict[str, float]]) -> np.ndarray:\n",
    "    pts = np.array([[d[\"x\"], d[\"y\"], d.get(\"z\", 0.0)] for d in lms], dtype=np.float32)  # (21,3)\n",
    "    wrist_xy = pts[0, :2].copy()\n",
    "    pts[:, :2] -= wrist_xy\n",
    "    span = np.linalg.norm(pts[5, :2] - pts[17, :2]) + 1e-6\n",
    "    pts[:, :2] /= span\n",
    "    pts[:, 2]  /= span\n",
    "    return pts.flatten()  # (63,)\n",
    "\n",
    "def maybe_load_json(path_dir: str) -> Optional[List[Dict[str, Any]]]:\n",
    "    for name in ASSERT_JSON:\n",
    "        p = os.path.join(path_dir, name)\n",
    "        if os.path.isfile(p):\n",
    "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1593f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: laad alle JSONs en vorm X, y\n",
    "X, y, metas = [], [], []  # metas: (label, image_file)\n",
    "missing = []\n",
    "\n",
    "for label in classes:\n",
    "    folder = os.path.join(DATASET_ROOT, label)\n",
    "    data = maybe_load_json(folder)\n",
    "    if not data:\n",
    "        missing.append(label)\n",
    "        continue\n",
    "    for entry in data:\n",
    "        lms = entry.get(\"landmarks\")\n",
    "        if not lms or len(lms) != 21:\n",
    "            continue\n",
    "        feat = preprocess_landmarks(lms)  # 63D\n",
    "        X.append(feat)\n",
    "        y.append(class_to_idx[label])\n",
    "        metas.append((label, entry.get(\"image\") or entry.get(\"image_file\") or \"\"))\n",
    "        \n",
    "X = np.stack(X).astype(np.float32)\n",
    "y = np.array(y, dtype=np.int64)\n",
    "print(\"Samples:\", len(y), \"Dim:\", X.shape, \"Missings(json):\", missing[:3], \"â€¦\")\n",
    "assert X.shape[1] == 63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24635861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: stratified splits\n",
    "test_size = 0.15\n",
    "val_size  = 0.15\n",
    "\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=SEED)\n",
    "train_val_idx, test_idx = next(sss1.split(X, y))\n",
    "\n",
    "X_train_val, y_train_val = X[train_val_idx], y[train_val_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "# Val t.o.v. totale set => verhouding op train_val bepalen:\n",
    "val_ratio_rel = val_size / (1.0 - test_size)  # bv. 0.15 / 0.85\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio_rel, random_state=SEED)\n",
    "train_idx, val_idx = next(sss2.split(X_train_val, y_train_val))\n",
    "\n",
    "X_train, y_train = X_train_val[train_idx], y_train_val[train_idx]\n",
    "X_val,   y_val   = X_train_val[val_idx], y_train_val[val_idx]\n",
    "\n",
    "for name, yy in [(\"train\", y_train), (\"val\", y_val), (\"test\", y_test)]:\n",
    "    print(name, \"size:\", len(yy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: torch datasets/dataloaders\n",
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, augment: bool = False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = self.X[idx].copy()\n",
    "        if self.augment:\n",
    "            # lichte jitter op x,y,z (mean 0, std 0.01)\n",
    "            noise = np.random.normal(0, 0.01, size=x.shape).astype(np.float32)\n",
    "            x += noise\n",
    "        return torch.from_numpy(x), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "BATCH = 256\n",
    "train_ds = LandmarkDataset(X_train, y_train, augment=True)\n",
    "val_ds   = LandmarkDataset(X_val,   y_val,   augment=False)\n",
    "test_ds  = LandmarkDataset(X_test,  y_test,  augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e328a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: model + training\n",
    "N_FEAT = 63\n",
    "N_CLS  = len(classes)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=N_FEAT, n_classes=N_CLS):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "    def forward(self, x):  # x: (B,63)\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP().to(DEVICE)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "def run_epoch(loader, train: bool):\n",
    "    model.train(train)\n",
    "    total_loss, preds, gts = 0.0, [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True).float()\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = crit(logits, yb)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total_loss += loss.item() * yb.size(0)\n",
    "        preds.extend(torch.argmax(logits, dim=1).detach().cpu().tolist())\n",
    "        gts.extend(yb.detach().cpu().tolist())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average=\"macro\", zero_division=0)\n",
    "    return avg_loss, acc, f1m\n",
    "\n",
    "BEST_VAL = math.inf\n",
    "PATIENCE, bad = 10, 0\n",
    "EPOCHS = 50\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_f1 = run_epoch(train_loader, True)\n",
    "    va_loss, va_acc, va_f1 = run_epoch(val_loader, False)\n",
    "    sched.step(va_loss)\n",
    "    print(f\"ep{ep:03d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} \"\n",
    "          f\"| val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f}\")\n",
    "\n",
    "    if va_loss < BEST_VAL - 1e-4:\n",
    "        BEST_VAL = va_loss\n",
    "        bad = 0\n",
    "        torch.save(model.state_dict(), \"./annotations/asl_mlp_best.pth\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# laad best\n",
    "model.load_state_dict(torch.load(\"./annotations/asl_mlp_best.pth\", map_location=DEVICE))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: evaluatie\n",
    "def predict_all(loader):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE).float()\n",
    "            logits = model(xb)\n",
    "            pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            y_true.extend(yb.numpy())\n",
    "            y_pred.extend(pred)\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "y_true, y_pred = predict_all(test_loader)\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "labels = sorted(np.unique(y_true))\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels,\n",
    "    target_names=[idx_to_class[i] for i in labels],\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(N_CLS)))\n",
    "fig = plt.figure(figsize=(10, 9))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix (test)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(N_CLS)\n",
    "plt.xticks(tick_marks, [idx_to_class[i] for i in range(N_CLS)], rotation=90)\n",
    "plt.yticks(tick_marks, [idx_to_class[i] for i in range(N_CLS)])\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: export\n",
    "# state_dict\n",
    "torch.save(model.state_dict(), \"./annotations/asl_mlp_state_dict.pth\")\n",
    "\n",
    "# TorchScript (script)\n",
    "scripted = torch.jit.script(model.cpu())\n",
    "scripted.save(\"./annotations/asl_mlp_script.pt\")\n",
    "\n",
    "# ONNX\n",
    "dummy = torch.randn(1, 63, dtype=torch.float32)\n",
    "torch.onnx.export(\n",
    "    model.cpu(), dummy, \"./annotations/asl_mlp.onnx\",\n",
    "    input_names=[\"x\"], output_names=[\"logits\"],\n",
    "    dynamic_axes={\"x\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "    opset_version=17\n",
    ")\n",
    "print(\"Exported to ./annotations/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: webcam inference\n",
    "# Zorg dat mediapipe en opencv beschikbaar zijn.\n",
    "mp_hands = mp_hands.Hands(\n",
    "    static_image_mode=False, max_num_hands=1, model_complexity=1,\n",
    "    min_detection_confidence=0.6, min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "def preprocess_from_mp(lmk_list) -> np.ndarray:\n",
    "    # zelfde normalisatie als tijdens training\n",
    "    pts = np.array([[lm.x, lm.y, getattr(lm, \"z\", 0.0)] for lm in lmk_list], dtype=np.float32)\n",
    "    wrist_xy = pts[0, :2].copy()\n",
    "    pts[:, :2] -= wrist_xy\n",
    "    span = np.linalg.norm(pts[5, :2] - pts[17, :2]) + 1e-6\n",
    "    pts[:, :2] /= span\n",
    "    pts[:, 2]  /= span\n",
    "    return pts.flatten()\n",
    "\n",
    "# Herlaad model en labelmap op CPU of GPU\n",
    "model.load_state_dict(torch.load(\"./annotations/asl_mlp_best.pth\", map_location=DEVICE))\n",
    "model.eval().to(DEVICE)\n",
    "with open(\"./annotations/label_map.json\", \"r\") as f:\n",
    "    class_to_idx = json.load(f)[\"class_to_idx\"]\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"[ERR] camera niet open\")\n",
    "else:\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "        rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        res = mp_hands.process(rgb)\n",
    "        pred_label = None\n",
    "\n",
    "        if res.multi_hand_landmarks:\n",
    "            lmk = res.multi_hand_landmarks[0].landmark\n",
    "            feat = preprocess_from_mp(lmk)\n",
    "            with torch.no_grad():\n",
    "                xb = torch.from_numpy(feat).unsqueeze(0).to(DEVICE)\n",
    "                logits = model(xb.float())\n",
    "                prob = torch.softmax(logits, dim=1)\n",
    "                idx = int(torch.argmax(prob, dim=1).item())\n",
    "                pred_label = idx_to_class[idx]\n",
    "                conf = float(prob[0, idx].cpu())\n",
    "            # teken landmarks\n",
    "            mp_drawing = cv\n",
    "            for lm in lmk:\n",
    "                h, w = frame.shape[:2]\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                cv.circle(frame, (cx, cy), 3, (0,255,0), -1)\n",
    "            cv.putText(frame, f\"{pred_label} ({conf:.2f})\", (10, 30),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "        cv.imshow(\"ASL landmarks classifier (MLP)\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
